name: üîç The Mystery Archives - Automated Mystery Shorts Pipeline

on:
  workflow_dispatch:
    inputs:
      platforms:
        description: 'Platforms to upload to (comma-separated: youtube,tiktok,instagram,facebook,makecom)'
        required: false
        default: 'youtube,facebook'
      force_all:
        description: 'Force upload to all enabled platforms'
        required: false
        type: boolean
        default: false
      ignore_schedule:
        description: 'Ignore optimal timing and post immediately'
        required: false
        type: boolean
        default: false
      mystery_type:
        description: 'Mystery category (disappearance, crime, historical, conspiracy, auto)'
        required: false
        default: 'auto'
      intensity:
        description: 'Content intensity (aggressive, balanced, inspirational)'
        required: false
        default: 'balanced'
        
  schedule:
    # This schedule is now precise, triggering only at the specified optimal times in UTC.
    # ET/PT times are approximate and can vary with daylight saving.

    # Monday
    - cron: '0 19 * * MON'    # 19:00 UTC (‚âà 3 PM ET / 12 PM PT)
    - cron: '0 23 * * MON'    # 23:00 UTC (‚âà 7 PM ET / 4 PM PT)

    # Tuesday
    - cron: '0 18 * * TUE'    # 18:00 UTC (‚âà 2 PM ET / 11 AM PT)
    - cron: '0 22 * * TUE'    # 22:00 UTC (‚âà 6 PM ET / 3 PM PT)
    - cron: '0 2 * * WED'     # 02:00 UTC next day (‚âà 10 PM ET / 7 PM PT)

    # Wednesday
    - cron: '0 19 * * WED'    # 19:00 UTC
    - cron: '0 23 * * WED'    # 23:00 UTC

    # Thursday
    - cron: '0 19 * * THU'    # 19:00 UTC
    - cron: '0 23 * * THU'    # 23:00 UTC

    # Friday
    - cron: '0 18 * * FRI'    # 18:00 UTC
    - cron: '0 22 * * FRI'    # 22:00 UTC
    - cron: '0 2 * * SAT'     # 02:00 UTC

    # Saturday
    - cron: '0 18 * * SAT'    # 18:00 UTC
    - cron: '0 22 * * SAT'    # 22:00 UTC

    # Sunday
    - cron: '0 19 * * SUN'    # 19:00 UTC
    - cron: '0 23 * * SUN'    # 23:00 UTC

jobs:
  build_and_upload:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: üîç Checkout Mystery Archives
        uses: actions/checkout@v4

      - name: üîê Validate secrets
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          MAKECOM_WEBHOOK_URL: ${{ secrets.MAKECOM_WEBHOOK_URL }}
        run: python .github/scripts/validate_secrets.py

      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üíæ Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-mystery-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-mystery-
            ${{ runner.os }}-pip-

      - name: üì¶ Install Python packages (for scheduler check)
        run: |
          python -m pip install --upgrade pip
          pip install pytz

      - name: üéØ Confirm Scheduled Run and Set Parameters
        id: schedule_check
        run: |
          python -c "
          import os
          from datetime import datetime
          import pytz

          # This script confirms if a run is a valid scheduled event or a forced manual run.
          # It uses UTC for all time comparisons to align with GitHub's cron scheduler.
          
          tz = pytz.timezone('UTC')
          current = datetime.now(tz)
          hour = current.hour
          minute = current.minute
          # weekday() in python: Monday is 0 and Sunday is 6. In cron, Sunday can be 0 or 7.
          # We use python's convention here and map cron's MON-SUN to 0-6.
          weekday = current.weekday()
          
          # This schedule must match the cron schedule defined in the workflow file.
          # Content types are assigned to ensure downstream steps have the required data.
          OPTIMAL_SCHEDULE = {
              # Monday (0)
              0: [
                  {'hour': 19, 'priority': 'high', 'type': 'unsolved_true_crime'},
                  {'hour': 23, 'priority': 'medium', 'type': 'historical_mysteries'}
              ],
              # Tuesday (1)
              1: [
                  {'hour': 18, 'priority': 'high', 'type': 'paranormal_hauntings'},
                  {'hour': 22, 'priority': 'highest', 'type': 'cosmic_and_sci_fi'}
              ],
              # Wednesday (2)
              2: [
                  {'hour': 2, 'priority': 'medium', 'type': 'high_strangeness'}, # From TUE night
                  {'hour': 19, 'priority': 'high', 'type': 'unsolved_true_crime'},
                  {'hour': 23, 'priority': 'medium', 'type': 'historical_mysteries'}
              ],
              # Thursday (3)
              3: [
                  {'hour': 19, 'priority': 'highest', 'type': 'cosmic_and_sci_fi'},
                  {'hour': 23, 'priority': 'high', 'type': 'paranormal_hauntings'}
              ],
              # Friday (4)
              4: [
                  {'hour': 18, 'priority': 'high', 'type': 'internet_and_modern'},
                  {'hour': 22, 'priority': 'highest', 'type': 'unsolved_true_crime'}
              ],
              # Saturday (5)
              5: [
                  {'hour': 2, 'priority': 'medium', 'type': 'high_strangeness'}, # From FRI night
                  {'hour': 18, 'priority': 'medium', 'type': 'historical_mysteries'},
                  {'hour': 22, 'priority': 'high', 'type': 'paranormal_hauntings'}
              ],
              # Sunday (6)
              6: [
                  {'hour': 19, 'priority': 'high', 'type': 'unsolved_true_crime'},
                  {'hour': 23, 'priority': 'highest', 'type': 'cosmic_and_sci_fi'}
              ]
          }
          
          should_post = False
          priority = 'low'
          content_type = 'off_schedule'
          
          # Check for manual override via workflow_dispatch input
          ignore_schedule = '${{ github.event.inputs.ignore_schedule }}' == 'true'
          is_scheduled_run = '${{ github.event_name }}' == 'schedule'
          
          if ignore_schedule:
              print('‚ö†Ô∏è Schedule check BYPASSED by user input (ignore_schedule: true).')
              should_post = True
              priority = 'manual'
              content_type = 'manual_dispatch'
              print('Setting content_type to \'manual_dispatch\' for this forced run.')
          
          # For a scheduled run, we assume it's the right time and just find the matching slot
          elif is_scheduled_run and weekday in OPTIMAL_SCHEDULE:
              # Check with a generous 5-minute tolerance to account for any slight runner delays
              for slot in OPTIMAL_SCHEDULE[weekday]:
                  if slot['hour'] == hour and abs(minute - 0) <= 5:
                      should_post = True
                      priority = slot['priority']
                      content_type = slot['type']
                      print(f'‚úÖ Scheduled run confirmed. Time is {current.strftime(\"%Y-%m-%d %H:%M UTC\")}')
                      print(f'   -> Content Type: {content_type}, Priority: {priority}')
                      break # Found the correct slot for this run
              if not should_post:
                  print(f'üö® Warning: A scheduled run was triggered, but no matching time slot was found within the 5-minute tolerance. Defaulting to not post.')
          
          elif not is_scheduled_run:
              print('‚ÑπÔ∏è This is a manual run without the ignore_schedule flag. No action will be taken as it is not a scheduled time.')

          # Write outputs for subsequent steps
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'should_post={str(should_post).lower()}\n')
              f.write(f'priority={priority}\n')
              # Use 'content_type' as the key to match the rest of the workflow
              f.write(f'content_type={content_type}\n')
              f.write(f'current_time={current.strftime(\"%Y-%m-%d %H:%M UTC\")}\n')
          "

      - name: üìÖ Display mystery scheduling decision
        run: |
          echo "‚è∞ Current Time (UTC): ${{ steps.schedule_check.outputs.current_time }}"
          echo "üéØ Should Post: ${{ steps.schedule_check.outputs.should_post }}"
          echo "‚≠ê Priority: ${{ steps.schedule_check.outputs.priority }}"
          echo "üîç Content Type: ${{ steps.schedule_check.outputs.content_type }}"
          echo ""
          echo "üí° Logic: This workflow runs ONLY at specific scheduled times or when manually forced."

      - name: ‚è∏Ô∏è Skip if not a valid run
        if: steps.schedule_check.outputs.should_post != 'true'
        run: |
          echo "‚è∏Ô∏è Skipping run - not a scheduled time or a forced manual run."
          echo "‚ÑπÔ∏è To run immediately, use the 'Run workflow' button with 'ignore_schedule' set to true."
          exit 0

      # ... (The rest of your workflow from "Cache apt packages" onwards remains IDENTICAL)
      # ... All `if: steps.schedule_check.outputs.should_post == 'true'` conditions will work as expected.
      
      - name: üì¶ Cache apt packages
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache@v4
        with:
          path: |
            /var/cache/apt/archives
            /var/lib/apt/lists
          key: ${{ runner.os }}-apt-mystery-${{ hashFiles('.github/workflows/mystery_shorts.yml') }}
          restore-keys: |
            ${{ runner.os }}-apt-mystery-
            ${{ runner.os }}-apt-

      - name: üîß Install system deps
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq \
            ffmpeg \
            libsm6 \
            libxext6 \
            imagemagick \
            fonts-dejavu-core \
            fonts-liberation \
            fonts-freefont-ttf \
            fonts-dejavu \
            espeak-ng
          echo "üîç System ready for mystery content generation"

      - name: üéôÔ∏è Cache Coqui models
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache@v4
        with:
          path: ~/.local/share/tts
          key: coqui-models-mystery-${{ runner.os }}

      - name: üìÅ Create tmp folder
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          mkdir -p tmp
          chmod -R 777 tmp
          echo "üîç Workspace ready for mystery archives"

      - name: üìã Restore platform config
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/platform_config.json
          key: platform-config-mystery-${{ github.run_number }}
          restore-keys: |
            platform-config-mystery-
            platform-config-

      - name: üìö Restore playlist config
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/playlist_config.json
          key: playlist-config-mystery-${{ github.run_number }}
          restore-keys: |
            playlist-config-mystery-
            playlist-config-

      - name: üìñ Restore content history
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/content_history.json
          key: content-history-mystery-${{ github.run_number }}
          restore-keys: |
            content-history-mystery-
            content-history-

      - name: üì¶ Install Python packages
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          python -m pip install --upgrade pip -q
          pip install -r requirements.txt -q
          echo "üîç Python dependencies installed"

      - name: üéµ Download background music library
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          echo "üéµ Downloading copyright-free dark ambient music..."
          python .github/scripts/download_music.py --download-all
        continue-on-error: true

      - name: üîç Fetch trending mystery topics
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
          MYSTERY_TYPE: ${{ github.event.inputs.mystery_type }}
        run: |
          echo "üîç Fetching trending mystery topics..."
          python .github/scripts/fetch_trending.py

      - name: ‚úçÔ∏è Generate mystery script
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
          PRIORITY: ${{ steps.schedule_check.outputs.priority }}
          MYSTERY_TYPE: ${{ github.event.inputs.mystery_type }}
        run: python .github/scripts/generate_trending_and_script.py

      - name: üéôÔ∏è Generate mysterious voiceover
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/generate_tts.py

      - name: üé¨ Create film noir mystery video
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/create_video.py

      - name: üñºÔ∏è Generate mysterious thumbnail
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/generate_thumbnail.py

      - name: üßπ Clean up temporary files
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          find tmp -name "scene_*.jpg" -type f -delete 2>/dev/null || true
          find tmp -name "*_noir.jpg" -type f -delete 2>/dev/null || true
          rm -f tmp/short_ready.mp4 2>/dev/null || true
          echo "üßπ Cleaned up temporary files"

      - name: üì§ Upload to multiple platforms
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          TIKTOK_ACCESS_TOKEN: ${{ secrets.TIKTOK_ACCESS_TOKEN }}
          INSTAGRAM_ACCESS_TOKEN: ${{ secrets.INSTAGRAM_ACCESS_TOKEN }}
          INSTAGRAM_ACCOUNT_ID: ${{ secrets.INSTAGRAM_ACCOUNT_ID }}
          FACEBOOK_PAGE_ID: ${{ secrets.FACEBOOK_PAGE_ID }}
          FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
          MAKECOM_WEBHOOK_URL: ${{ secrets.MAKECOM_WEBHOOK_URL }}
          PLATFORMS: ${{ github.event.inputs.platforms }}
          FORCE_ALL: ${{ github.event.inputs.force_all }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/upload_multiplatform.py

      - name: üîé Find Renamed Video and Compress for Cloudinary
        if: steps.schedule_check.outputs.should_post == 'true'
        id: find_and_compress
        run: |
          # Find the video file in the tmp directory, which was likely renamed by the uploader.
          # This handles cases where it's `short.mp4` or `SEO-Optimized Title.mp4`.
          VIDEO_PATH=$(find tmp -name "*.mp4" -type f | head -n 1)

          if [ -z "$VIDEO_PATH" ]; then
            echo "‚ùå CRITICAL: No video file found in tmp/ directory after upload step!"
            exit 1
          fi

          echo "Found original video for compression: $VIDEO_PATH"
          ls -lh "$VIDEO_PATH"

          # Define the output path for the compressed version
          COMPRESSED_PATH="tmp/compressed_for_makecom.mp4"

          # Re-compress the FOUND video with a much lower bitrate
          ffmpeg -i "$VIDEO_PATH" -c:v libx264 -preset veryfast -crf 28 -b:v 800k -c:a aac -b:a 128k -y "$COMPRESSED_PATH"
          
          echo "Compressed video created:"
          ls -lh "$COMPRESSED_PATH"
          
          # Output the paths for subsequent steps
          echo "original_path=$VIDEO_PATH" >> $GITHUB_OUTPUT
          echo "compressed_path=$(realpath $COMPRESSED_PATH)" >> $GITHUB_OUTPUT

      - name: Prepare Make.com payload
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        id: makecom_prep
        run: |
          TITLE=$(jq -r '.title' tmp/script.json)
          DESCRIPTION=$(jq -r '.description' tmp/script.json)
          HASHTAGS=$(jq -r '.hashtags | join(" ")' tmp/script.json)
          
          # ‚úÖ CRITICAL CHANGE: Use the SEO-named path from the find_and_compress step
          VIDEO_PATH="${{ steps.find_and_compress.outputs.original_path }}"
          
          VIDEO_SIZE=$(stat -c%s "$VIDEO_PATH" 2>/dev/null || stat -f%z "$VIDEO_PATH")
          YOUTUBE_URL=""
          FACEBOOK_URL=""
          if [ -f tmp/multiplatform_log.json ]; then
            YOUTUBE_URL=$(jq -r '.[-1].results[] | select(.platform=="youtube") | .url // ""' tmp/multiplatform_log.json)
            FACEBOOK_URL=$(jq -r '.[-1].results[] | select(.platform=="facebook") | .url // ""' tmp/multiplatform_log.json)
          fi
          cat > tmp/makecom_payload.json <<EOF
          {
            "title": "$TITLE",
            "description": "$DESCRIPTION",
            "hashtags": "$HASHTAGS",
            "video_name": "$(basename "$VIDEO_PATH")",
            "video_size_mb": $(echo "scale=2; $VIDEO_SIZE/1024/1024" | bc),
            "workflow_run": "${{ github.run_number }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "platform_urls": {
              "youtube": "$YOUTUBE_URL",
              "facebook": "$FACEBOOK_URL"
            }
          }
          EOF
          echo "‚úÖ Make.com payload prepared"

      - name: Upload video to Cloudinary for Make.com
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        id: upload_temp
        env:
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
          # ‚úÖ CRITICAL CHANGE: Use the correct path from the new step
          VIDEO_TO_UPLOAD: ${{ steps.find_and_compress.outputs.compressed_path }}
        run: |
          echo "üì§ Uploading COMPRESSED video to Cloudinary..."
          python .github/scripts/upload_to_cloudinary.py
          VIDEO_URL=$(cat tmp/video_url.txt)
          echo "video_url=$VIDEO_URL" >> $GITHUB_OUTPUT
          echo "‚úÖ Video URL: $VIDEO_URL"

      - name: Send to Make.com webhook
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        run: |
          PAYLOAD=$(cat tmp/makecom_payload.json)
          VIDEO_URL="${{ steps.upload_temp.outputs.video_url }}"
          
          # ‚úÖ CORRECT WAY to get the SEO-optimized video name
          VIDEO_NAME=$(basename "${{ steps.find_and_compress.outputs.original_path }}")
          
          curl -X POST "${{ secrets.MAKECOM_WEBHOOK_URL }}" \
            -H "Content-Type: application/json" \
            -d "{
              \"video_url\": \"$VIDEO_URL\",
              \"video_name\": \"$VIDEO_NAME\",
              \"metadata\": $PAYLOAD,
              \"artifact_url\": \"https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\",
              \"github\": {
                \"run_id\": \"${{ github.run_id }}\",
                \"run_number\": \"${{ github.run_number }}\",
                \"repository\": \"${{ github.repository }}\"
              }
            }"
          echo "‚úÖ Webhook sent to Make.com"
          
      - name: üìö Organize into mysterious playlists
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/manage_playlists.py

      - name: üíæ Save platform config
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/platform_config.json
          key: platform-config-mystery-${{ github.run_number }}

      - name: üíæ Save playlist config
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/playlist_config.json
          key: playlist-config-mystery-${{ github.run_number }}

      - name: üíæ Save content history
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/content_history.json
          key: content-history-mystery-${{ github.run_number }}

      - name: üì¶ Upload artifacts
        uses: actions/upload-artifact@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          name: mysterious-short-${{ github.run_number }}
          path: |
            tmp/*.mp4
            tmp/thumbnail.png
            tmp/script.json
            tmp/content_history.json
            tmp/multiplatform_log.json
            tmp/voice.mp3
          retention-days: 30

      - name: üìã Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs-mystery-${{ github.run_number }}
          path: tmp/*.log
          retention-days: 7

      - name: üî• Workflow Summary
        if: always()
        run: |
          echo "## üîç Mystery Archives - Pipeline Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**‚è∞ Run Time (UTC):** \`${{ steps.schedule_check.outputs.current_time }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**‚úÖ Posted This Run:** \`${{ steps.schedule_check.outputs.should_post }}\`" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ steps.schedule_check.outputs.should_post }}" == "true" ]]; then
            echo "**‚≠ê Priority:** \`${{ steps.schedule_check.outputs.priority }}\`" >> $GITHUB_STEP_SUMMARY
            echo "**üîç Content Type:** \`${{ steps.schedule_check.outputs.content_type }}\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "> The workflow did not run because it was not triggered at a scheduled time or manually forced with the 'ignore_schedule' option." >> $GITHUB_STEP_SUMMARY
          fi